#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Call as:

    MatchPageviews.py prefix pagetitles.txt pagecounts+++-totals.bz2 pagecounts+++-totals.bz2, ...

total pagecount files (per month) can be obtained from http://dumps.wikimedia.org/other/pagecounts-ez/merged/ 
prefix denotes the name used for the appropriate wiki project, e.g. 'en.z' for en.wikipedia (note this is different from the normal dumps, which just use 'en')
'The project is one of b (wikibooks), k (wiktionary), n (wikinews), o (wikivoyage), q (wikiquote), s (wikisource), v (wikiversity), z (wikipedia).'

pagetitles.txt gives the page titles (spaces are substituted for _, and cgi-escapes done). Any text before the last tab is taken as a row name, to output
any number of pagecounts files can be provided, and the page visits in each file added to the output

In particular, you might want to pass in a list of pagetitles as generated by WikiDataMap.py

WikiDataMap.py taxonomy.tsv wikidata-20151005-all.json.gz enwiki > map_file.txt
cut 1,4 map_file.txt | sort -n | uniq | MatchPageviews.py en.z - pagecounts-2015-09-views-ge-5-totals.bz2 pagecounts-2015-08-views-ge-5-totals.bz2

sort -k 3,3nr -t$'\t' foo | less

may need to 

"""
import sys
import csv
import re
import resource
import fileinput
import collections
import urllib.parse

def warn(*objs):
    print(*objs, file=sys.stderr)

def memory_usage_resource():
    import resource
    rusage_denom = 1024.
    if sys.platform == 'darwin':
        # ... it seems that in OSX the output is different units ...
        rusage_denom = rusage_denom * rusage_denom
    mem = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / rusage_denom
    return mem

def sensible_sum(l):
    '''Treat None as NA, e.g. if l==[] or l == [None, None] return None'''
    l = [x for x in l if x is not None]
    if len(l):
        return sum(l)
    else:
        return None

def strNone(x):
    return str(x) if x is not None else ''

if len(sys.argv) < 4:
    sys.exit('Provide the name of a wiki project (e.g. en.z, or en.b) as the first argument, the name of a titles file as the second, and pagecounts files as further args')

linetitles={}
lines = []
pageview_files = collections.OrderedDict()
for fn in sys.argv[3:]:
    if fn not in pageview_files: #make unique
        pageview_files[fn]=len(pageview_files)
counts = []
try:
    title_file = fileinput.input(sys.argv[2])
except IOError as e:
    sys.exit("I/O error({0}): {1}".format(e.errno, e.strerror))
    
    
for line in title_file:
    if (title_file.filelineno() % 500000 == 0):
        warn("{} entries read from title file: mem usage {} Mb".format(title_file.filelineno(), memory_usage_resource()))
    line = line.rstrip('\r\n')
    lines.append(line)
    if title_file.isfirstline():
        counts.append(list(pageview_files.keys())) #headers
    else:
        wikititle = line.rsplit("\t",1)[-1]
        if wikititle != "":
            wikititle = wikititle.replace(" ","_")
            wikititle = urllib.parse.quote(wikititle)
            linetitles[wikititle] = len(lines)-1
            counts.append([None] * len(pageview_files))
        else:
            counts.append([])
warn("Done: {} entries read.".format(len(lines)))

match_project = (sys.argv[1]+" ").encode() #pageviews have project name (ascii) followed by space, followed by uri-escaped title, followed by space, followed by integer
fp = fileinput.input(pageview_files,openhook=fileinput.hook_compressed)
old_filename = ''
filenum = -1
problem_lines = {x:[] for x in pageview_files} #there are apparently some errors in the unicode dumps
for line in fp:
    if (fp.filelineno() % 1000000 == 0):
        warn("{} entries read from pagecount file {} ({}): mem usage {} Mb".format(fp.filelineno(), pageview_files[fp.filename()], fp.filename(), memory_usage_resource()))
    if line.startswith(match_project):
        try:
            fields = line.decode('UTF-8').rstrip('\r\n').split(" ")
            counts[linetitles[fields[1]]][pageview_files[fp.filename()]] = int(fields[2])
        except LookupError:
            pass
        except UnicodeDecodeError:
            problem_lines[fp.filename()].append(fp.filelineno())
for fn,prob_lines in problem_lines.items():
    if len(prob_lines):
        warn("Problem decoding certain lines in {}. The following lines have been ignored: {}.".format(fn, ", ".join([str(x) for x in prob_lines])))
            
firstline = 1
for line, vals in zip(lines, counts):
    if len(pageview_files)>1:
        if firstline:
            print("\t".join([line] + vals + ['total_pageviews']))
            firstline = 0
        else:
            print("\t".join([line] + map(strNone,vals) + [strNone(sensible_sum(vals))]))
    else:
        print("\t".join([line] + map(strNone,vals)))